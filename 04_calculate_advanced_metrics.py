import copy
import multiprocessing
import sys

from joblib import Parallel, delayed

from resources.data_types import COMPUTED_METRIC

sys.dont_write_bytecode = True
import importlib

from misc.config import Config
from pandarallel import pandarallel

pandarallel.initialize(progress_bar=True)

config = Config()


if config.COMPUTED_METRICS == ["_ALL"]:
    # ensure that STANDARD_AUC is run last so that all other metrics are already precomputed
    config.COMPUTED_METRICS = [
        sc.name
        for sc in COMPUTED_METRIC
        if sc != COMPUTED_METRIC.STANDARD_AUC and sc != COMPUTED_METRIC.TIMELAG_METRIC
    ] + [COMPUTED_METRIC.TIMELAG_METRIC.name, COMPUTED_METRIC.STANDARD_AUC.name]


print("computung the following metrics: " + ",".join(config.COMPUTED_METRICS))


# -> hier erstmal eine liste mit den combinations von metriken etc. erstellen --> dann schÃ¶n gepflegt aufrufen das ganze
print(config.COMPUTED_METRICS)


def _run_single_metric(m):
    m[0](*m[1:])


all_datasets = copy.deepcopy(config.EXP_GRID_DATASET)

for ds in all_datasets:
    config.EXP_GRID_DATASET = [ds]

    for computed_metric in config.COMPUTED_METRICS:
        print(computed_metric)
        computed_metric_class = getattr(
            importlib.import_module("metrics.computed." + computed_metric),
            computed_metric,
        )
        computed_metric_class = computed_metric_class(config)
        metrics_to_compute = computed_metric_class.get_all_metric_jobs()

        Parallel(
            n_jobs=multiprocessing.cpu_count(),
            backend="multiprocessing",
            verbose=10,
            # n_jobs=2, # never run as single processes -> weird bugs occur!
        )(delayed(_run_single_metric)(m) for (m) in metrics_to_compute)
